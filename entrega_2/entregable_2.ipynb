{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import redshift_connector\n",
    "from dotenv import dotenv_values\n",
    "import psycopg2\n",
    "import os\n",
    "from io import StringIO\n",
    "import sqlalchemy as sa\n",
    "from sqlalchemy.engine.url import URL\n",
    "\n",
    "\n",
    "    \n",
    "env_vars = dotenv_values('.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function = 'TIME_SERIES_WEEKLY'\n",
    "# Big Five Tech: Google, Amazon, Meta, Apple, and Microsoft (GAMAM)\n",
    "symbols = ['GOOG', 'AMZN', 'METV', 'AAPL', 'MSFT']\n",
    "api_key = 'WNHSBPLUX5B8HNMZ'\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for symbol in symbols:\n",
    "    url = f'https://www.alphavantage.co/query?function={function}&symbol={symbol}&apikey={api_key}'\n",
    "    r = requests.get(url)\n",
    "    data = r.json()\n",
    "\n",
    "    symbol_df = pd.DataFrame(data['Weekly Time Series'])\n",
    "    symbol_df = symbol_df.T\n",
    "    symbol_df.reset_index(inplace=True)\n",
    "    symbol_df.rename(columns={'index':'week_from', '1. open':'open', '2. high':'high', '3. low': 'low', \n",
    "                       '4. close':'close', '5. volume':'volume'}, inplace=True)\n",
    "    \n",
    "    symbol_df['symbol'] = data['Meta Data']['2. Symbol']\n",
    "\n",
    "    symbol_df['open'] = pd.to_numeric(symbol_df['open'])\n",
    "    symbol_df['close'] = pd.to_numeric(symbol_df['close'])\n",
    "    symbol_df['avg'] = (symbol_df['open'] + symbol_df['close'])/2\n",
    "    symbol_df['pk'] = symbol_df['symbol']+symbol_df['week_from']\n",
    "\n",
    "    # symbol_df['avg'] = symbol_df[['close', 'open']].mean(axis=1)\n",
    "    \n",
    "    df = pd.concat([df, symbol_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4289"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = URL.create(\n",
    "drivername='redshift+redshift_connector', # indicate redshift_connector driver and dialect will be used\n",
    "host=env_vars['HOST'], # Amazon Redshift host\n",
    "port=int(env_vars['PORT']), # Amazon Redshift port\n",
    "database=env_vars['DATABASE'], # Amazon Redshift database\n",
    "username=env_vars['USER'], # Amazon Redshift username\n",
    "password=env_vars['PASSWORD'] # Amazon Redshift password\n",
    ")\n",
    "\n",
    "engine = sa.create_engine(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "DatatypeMismatch",
     "evalue": "column \"volume\" is of type bigint but expression is of type character varying\nHINT:  You will need to rewrite or cast the expression.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDatatypeMismatch\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 23\u001b[0m\n\u001b[0;32m     10\u001b[0m cursor \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39mcursor()\n\u001b[0;32m     12\u001b[0m sql_transaction \u001b[39m=\u001b[39m \u001b[39m'''\u001b[39m\u001b[39m begin transaction;\u001b[39m\n\u001b[0;32m     13\u001b[0m \n\u001b[0;32m     14\u001b[0m \u001b[39m                      delete from laureanoengulian_coderhouse.big_five_weekly using laureanoengulian_coderhouse.stage \u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[39m                      end transaction;\u001b[39m\n\u001b[0;32m     21\u001b[0m \u001b[39m                  \u001b[39m\u001b[39m'''\u001b[39m\n\u001b[1;32m---> 23\u001b[0m cursor\u001b[39m.\u001b[39;49mexecute(sql_transaction)\n\u001b[0;32m     24\u001b[0m conn\u001b[39m.\u001b[39mcommit()\n\u001b[0;32m     26\u001b[0m drop_tmp \u001b[39m=\u001b[39m \u001b[39m'''\u001b[39m\u001b[39mdrop table if exists laureanoengulian_coderhouse.stage;\u001b[39m\u001b[39m'''\u001b[39m\n",
      "\u001b[1;31mDatatypeMismatch\u001b[0m: column \"volume\" is of type bigint but expression is of type character varying\nHINT:  You will need to rewrite or cast the expression.\n"
     ]
    }
   ],
   "source": [
    "# Connect to Redshift using psycopg2\n",
    "conn = psycopg2.connect(\n",
    "    host=env_vars['HOST'],\n",
    "    port=int(env_vars['PORT']),\n",
    "    database=env_vars['DATABASE'],\n",
    "    user=env_vars['USER'],\n",
    "    password=env_vars['PASSWORD']\n",
    " )\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create table if not exists\n",
    "tmp_table = '''CREATE TABLE IF NOT EXISTS laureanoengulian_coderhouse.stage(\n",
    "                        \"week_from\" date not null,\n",
    "                        \"open\" decimal(38, 4) not null,\n",
    "                        \"high\" decimal(38, 4) not null,\n",
    "                        \"low\" decimal(38, 4) not null,\n",
    "                        \"close\" decimal(38, 4) not null,\n",
    "                        \"volume\" bigint not null,\n",
    "                        \"symbol\" varchar(15) not null,\n",
    "                        \"avg\" decimal(38,4) not null,\n",
    "                        \"pk\" varchar(60));\n",
    "                     '''\n",
    "\n",
    "cursor.execute(tmp_table)\n",
    "conn.commit()\n",
    "\n",
    "df.to_sql(name='stage',\n",
    "          con=engine,\n",
    "          if_exists='replace',\n",
    "          index=False)\n",
    "          # method=callable)\n",
    "\n",
    "sql_transaction = ''' begin transaction;\n",
    "\n",
    "                      delete from laureanoengulian_coderhouse.big_five_weekly using laureanoengulian_coderhouse.stage \n",
    "                      where big_five_weekly.pk = stage.pk;\n",
    "\n",
    "                      insert into laureanoengulian_coderhouse.big_five_weekly\n",
    "                      select * from laureanoengulian_coderhouse.stage;\n",
    "\n",
    "                      end transaction;\n",
    "                  '''\n",
    "\n",
    "cursor.execute(sql_transaction)\n",
    "conn.commit()\n",
    "\n",
    "drop_tmp = '''drop table if exists laureanoengulian_coderhouse.stage;'''\n",
    "\n",
    "cursor.execute(sql_transaction)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Redshift using psycopg2\n",
    "conn = psycopg2.connect(\n",
    "    host=env_vars['HOST'],\n",
    "    port=int(env_vars['PORT']),\n",
    "    database=env_vars['DATABASE'],\n",
    "    user=env_vars['USER'],\n",
    "    password=env_vars['PASSWORD']\n",
    " )\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# # Eliminate the table if exists\n",
    "# cleaner_query = '''DROP TABLE IF EXISTS laureanoengulian_coderhouse.big_five_weekly;'''\n",
    "# cursor.execute(cleaner_query)\n",
    "# conn.commit()\n",
    "\n",
    "# # Create table if not exists\n",
    "# create_table_query = '''CREATE TABLE IF NOT EXISTS laureanoengulian_coderhouse.big_five_weekly(\n",
    "#                         \"week_from\" date not null,\n",
    "#                         \"open\" decimal(38, 4) not null,\n",
    "#                         \"high\" decimal(38, 4) not null,\n",
    "#                         \"low\" decimal(38, 4) not null,\n",
    "#                         \"close\" decimal(38, 4) not null,\n",
    "#                         \"volume\" bigint not null,\n",
    "#                         \"symbol\" varchar(15) not null,\n",
    "#                         \"avg\" decimal(38,4) not null,\n",
    "#                         \"pk\" varchar(60));\n",
    "#                      '''\n",
    "\n",
    "# cursor.execute(create_table_query)\n",
    "# conn.commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
